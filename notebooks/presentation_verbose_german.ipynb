{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Was ist Data Science?\n",
    "\n",
    "Kern: Aus histoischen Daten Vorhersagen treffen.\n",
    "\n",
    "Dafür gibt es viele Algorithmen.\n",
    "Eine einfache und weit verbreitete ist die lineare Regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineare Regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei vielen Analysen wollen wir eine Zahl $y$, gegeben einige Eingabeparameter $x$, vorhersagen -- diese Problemklasse nennt man \"Regression\".\n",
    "Ein Beispiel wäre, dass wir den Preis eines Hauses ($y$) prognostizieren wollen, gegeben einige Parameter ($x$) des Hauses (Anzahl Zimmer, Größe in $m²$, Alter, ...).\n",
    "\n",
    "Wir wollen also die Ausgaben einer unbekannte Funktion $f : \\mathbb{R}^n \\to \\mathbb{R}$ schätzen.\n",
    "Genauer, wir haben $N$ Beispiele $(x_i, f(x_i)) : i=0,..,N$ gegeben und wollen nun $f(x)$ für einige neue Punkte $x$ prognostizieren."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verwenden einen Mini-Datensatz der 1960 von Nancy Howell zum Studium des Volkes der ǃKung gesammelt wurde (https://en.wikipedia.org/wiki/%C7%83Kung_people) (und nur Personen <= 25 Jahre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Howell1_young.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"age\", y=\"height\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Beispiel besteht $x$ nur aus einer Ausprägung: \"age\", im Allgemeinen ist $x$ aber ein Vektor $(x_1, ..., x_n)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei *linerarer* Regression, nehmen wir als Ansatz/Modell eine lineare Funktion für $f$ an. In unserem Beispiel also $y = a\\cdot x + b$.\n",
    "Die beiden Koeffizienten $a$ und $b$ sind noch unbestimmt und sind die freien Parameter unseres Modells. Wir bestimmen $a$ und $b$ so, dass unsere Daten \"gut\" zu dem Modell passen.\n",
    "Weil wir (viel) mehr Datenpunkte als Parameter haben wird der Zusammenhang $y = a\\cdot x + b$ niemals *exakt* erfüllt sein (und das wäre sogar nichtmal gut!), wir wählen stattdessen $a$ und $b$ so, dass die *mittlere quadratische Abweichung* von $f$ und den Daten minimiert wird.\n",
    "\n",
    "In anderen Worten, wir wählen $a,b$ so, dass im Mittel über alle Datenpunkte $(x,y)$, $(a\\cdot x + b - y)^2$ möglichst klein wird.\n",
    "(die Abweichung vom Modell zur Realität, wobei wir Abweichungen quadratisch werten, d.h. größere Abweichungen werden stärker bestraft.)\n",
    "\n",
    "Nochmal genauer formuliert: Gegeben n Paare von Datenpunkten $(x^{(1)}, y^{(1)}), ..., (x^{(n)}, y^{(n)})$\n",
    "suchen wir $a,b$ so dass der Ausdruck\n",
    "\n",
    "$\\frac{1}{n} \\sum_{i=1}^n (a\\cdot x^{(i)} + b - y^{(i)})^2$\n",
    "\n",
    "minimal wird."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst teilen wir die Daten in 2 Teile: Trainingsmenge und eine Testmenge. Die Idee ist, dass wir unser Modell nur auf den Trainingsdaten anpassen und dann auf den Testdaten evaluieren.\n",
    "Die Testdaten sollten nicht in die Modellkonstruktion einfließen. Die Trainings- und Test-daten sollten nicht zusammenhängen. So etwas kann passieren, wenn die beiden Datenmengen nicht disjukt sind oder einige Test- und Trainingspunkte stark korreliert sind (z.B. bei Zeitreihen -- z.B. das Wetter heute und morgen ist oft ähnlich))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df.shape[0]\n",
    "n = int(0.7 * N)\n",
    "\n",
    "rng = np.random.default_rng(42) # get a random-number generator with fixed seed (-> reproducibility!)\n",
    "\n",
    "training_indices = list(rng.choice(range(0, N), n))\n",
    "test_indices = list(set(range(0, N)).difference(set(training_indices))) # super inefficient but we don't care for such small numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "x_train = df[[\"age\"]].iloc[training_indices]\n",
    "y_train = df[\"height\"].iloc[training_indices]\n",
    "\n",
    "x_test = df[[\"age\"]].iloc[test_indices]\n",
    "y_test = df[\"height\"].iloc[test_indices]\n",
    "\n",
    "\n",
    "linear_reg.fit(x_train,y_train) # berechnet a und b\n",
    "\n",
    "a = linear_reg.coef_[0]\n",
    "b = linear_reg.intercept_\n",
    "print(f\"a = {a}, b = {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(list(zip(x_train.iloc[:,0],y_train))).plot.scatter(x=0, y=1)\n",
    "y_pred_train = linear_reg.predict(x_train)\n",
    "y_pred_test = linear_reg.predict(x_test)\n",
    "\n",
    "ax.axline((0,b), slope=a, color=\"darkred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell-Evaluation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot der Residuen\n",
    "\n",
    "Erinnerung: wir haben Datenpunkte $(x^{(i)}, y^{(i)})$\n",
    "Sei $\\hat{y^{(i)}}$ die Vorhersage unseres Regressionsmodells für den $i$-ten Datenpunkt.\n",
    "Für jedes $i$ ist die Abweichung $r_i = \\hat{y^{(i)}} - y^{(i)}$. Diese nennen wir *Residuuen* und wenn unser Regressionsmodell auf die Daten passt, sollten diese Residuen keine systematischen Abweichungen (\"Bias\") zeigen.\n",
    "Wenn wir sie also plotten sollten sie zufällig um $0$ streuen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train = y_pred_train - y_train\n",
    "r_test = y_pred_test - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train.plot(style='.')\n",
    "r_test.plot(style='.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen keine systematische Verzerrung, also scheint unsere lineare Regression schon mal gut."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$\n",
    "\n",
    "Das simpleste Modell für die Zielvariable, wäre einfach den Mittelwert der Trainingsdaten zu nehmen.\n",
    "Wir wollen die mittlere quadratische Abweichung unseres Modells gegen dieses \"Mittelwert-Modell\" vergleichen.\n",
    "Im schlechtesten Fall liefern wir das selbe, das soll einen Wert von $0$ ergeben. Im besten Fall ist die Abweichung von den Daten $0$, dann soll unsere Bewertung $1$ sein.\n",
    "\n",
    "$R^2 = 1 - \\frac{\\frac{1}{n} \\sum_i (y^{(i)} - \\hat{y^{(i)} } )}{\\frac{1}{n} \\sum_i (y^{(i)} - \\bar{y})} = 1 - \\frac{\\sum_i (y^{(i)} - \\hat{y^{(i)} })}{\\sum_i (y^{(i)} - \\bar{y})}$\n",
    "\n",
    "(Bemerkung: Wir verwenden hier die R^2 Definition für Lineare Regression *mit* Intercept (d.h. b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Varianz (=Streuung) der Daten ist definiert als die mittlere quadratische Abweichung der Daten von ihrem Mittelwert $\\bar{y}$:\n",
    "\n",
    "$ \\frac{1}{n} \\sum_i (y^{(i)} - \\bar{y})^2 $\n",
    "\n",
    "Eine andere Interpretation von $R^2$ ist der Anteil der vom Modell \"erklärten\" Varianz der Daten. Eine Rechnung zeigt, dass man $R^2$ schreiben kann als\n",
    "\n",
    "$R^2 = \\frac{\\sum_i (\\hat{y^{(i)} } - \\bar{y})}{\\sum_i (y^{(i)} - \\bar{y})}$\n",
    "\n",
    "Oben steht die Varianz der Vorhersage, unten die Varianz der Daten, $R^2$ sagt also wie viel von der Varianz in den Daten sich durch die Vorhersage produzieren (und daher \"erklären\") lässt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train R2: {sklearn.metrics.r2_score(y_pred_test, y_test)}\")\n",
    "print(f\"Test R2: {sklearn.metrics.r2_score(y_pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over/Underfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von \"Overfitting\" spricht man wenn das Modell \"zu gut\" zu den Daten passt, d.h. es passt sehr gut auf die Trainingsdaten, aber generalisiert nicht auf neue Daten wie z.B. den Testdaten.\n",
    "Der Fehler (z.B. mittlere quadratische Abweichung) auf den Trainingsdaten ist sehr klein, auf den Testdaten aber sehr groß.\n",
    "Das gegenteilige Problem ist \"Underfitting\", d.h. das Modell ist nicht komplex genug, um sich den Daten anzupassen. Der Fehler (gemessen auf den Trainingsdaten) ist selbst nach Anpassung an die Trainingsdaten noch groß."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(weitere Erklärung https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt: Toronto Bike Sharing\n",
    "\n",
    "Wir haben Daten von Bike Share Toronto (https://bikesharetoronto.com/)\n",
    "Für jede Reise werden Daten (z.B. von wo nach wo, wie lange dauerte die Fahrt) gesammelt, die online verfügbar sind (https://open.toronto.ca/dataset/bike-share-toronto-ridership-data/).\n",
    "\n",
    "Wir wollen 1 Woche im Voraus vorhersagen, wie viele Räder an einem gewissen Tag an einer Station ausgeliehen werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach dem Installieren des Packets (siehe Setup.md)\n",
    "Das Herunterladen und Bereinigen der Daten ist am Einfachsten über das Skript aus dem \"entry_points\" Verzeichnis:\n",
    "\n",
    "``` $ poetry install ```\n",
    "\n",
    "``` (bike-share-py3.10) $ python entry_points/load_data.py ```\n",
    "\n",
    "Als Warnung: Die tägliche Arbeit eines Data Scientist besteht zu 80% daraus, Daten zu bereinigen und vielleicht zu 20% daraus statistische Modelle zu bauen und zu trainieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten\n",
    "\n",
    "Bike Share Toronto, ~630 Stationen und ~7000 Räder.\n",
    "\n",
    "Die Datenfelder sind\n",
    "* Trip ID [int]\n",
    "* Trip Duration [s, int]\n",
    "* Trip Start Station ID [int]\n",
    "* Trip Start time [timestamp]\n",
    "* Trip Start Station Name [string]\n",
    "* Trip End Station ID [int]\n",
    "* Trip End Time [timestamp]\n",
    "* Trip End Station Name [string]\n",
    "* Bike ID [int]\n",
    "* User type [string, eigentlich boolean 0/1 (member/casual)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritte \n",
    "1. Mache Dich mit den Daten vertraut (download, Einlesen)\n",
    "2. Hauptaufgabe:\n",
    "    a) Für jeden Tag und Station voraussagen, wie viele Fahrräder dort ausgeliehen werden.\n",
    "    b) Extrahiere aus den Daten weitere Features, die die Vorhersage verbessern.\n",
    "3. Mögliche Erweiterungen (erstmal ein Modell für Frage 2 bauen und evaluieren!):\n",
    " * Nutze weitere Datenquellen um die Vorhersage aus 2) zu verbessern (z.B. Wetter https://toronto.weatherstats.ca/download.html).\n",
    " * Was könnten andere Ziel-Variablen als \"tägliche Anzahl Ausleihvorgänge\" sein, die vielleicht für die Betreiber hilfreich(er) sind?\n",
    " * ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hinweise für Schritt 1 (Daten herunterladen, säubern und aggregieren)\n",
    "\n",
    "1. Das Environment bike_share aktivieren.\n",
    "\n",
    "2. Daten herunterladen und säubern, Annahme: wir sind im Projekt-Verzeichnis!\n",
    "\n",
    "``` (bike-share-py3.10) $ python entry_points/load_data.py ```\n",
    "\n",
    "3. Tägliche Ausleihzahlen berechnen\n",
    "\n",
    "``` (bike-share-py3.10) $ python entry_points/compute_counts.py ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "## Nützliche Dokumentationen\n",
    "https://pandas.pydata.org/docs/user_guide/indexing.html\n",
    "\n",
    "https://pandas.pydata.org/docs/user_guide/merging.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "\n",
    "## weitere Links\n",
    "https://bikesharetoronto.com/faq/\n",
    "\n",
    "https://www.kaggle.com/code/yclaudel/see-the-flow-of-bikes/notebook\n",
    "(da wird auch beschrieben, wie man an die Stations-Daten https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_information kommt)\n",
    "\n",
    "https://tellingstorieswithdata.com/inputs/pdfs/paper_one-2022-hudson_yuen.pdf\n",
    "\n",
    "https://toronto.weatherstats.ca/download.html (3 Jahre = 1095 Tage)\n",
    "\n",
    "https://opendata.stackexchange.com/questions/7793/age-weight-and-height-dataset (Referenz auf https://github.com/rmcelreath/rethinking/blob/master/data/Howell1.csv und https://github.com/rmcelreath/rethinking/blob/master/data/Howell2.csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike-share-EaMkQB_Z-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cbeb47078aa45888cfdfe1cd418c35bbe08d87096f232f3b2802300757ee231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
